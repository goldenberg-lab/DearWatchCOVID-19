{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost for ILI-onset prediction\n",
    "\n",
    "### License\n",
    "© Evidation Health, Inc. (2020), All rights reserved.\n",
    " \n",
    "Provided pursuant to a non-exclusive, non-transferable license to Vector Institute (“Licensee”) for the term of, and solely for use in performing the Institute’s obligations under, the Data Use and Non-Disclosure Agreement between Vector Institute and Evidation Health, Inc. dated April 8, 2020 (“Data Use Agreement”).  The Evidation Code shall be considered Evidation Confidential Information under the Data Use Agreement.\n",
    "\n",
    "Evidation reserves all right, title, ownership and interest in and to the Evidation Code existing prior to and after the Effective Date, or created or generated by Evidation at any time, subject to the license granted to Licensee, including Derivative Works, whether created by Evidation or Licensee, of Evidation Code, unless otherwise specified in the Data Use Agreement. At Evidation’s request, which may be made at any time, Licensee shall promptly deliver to Evidation a copy of all Evidation Code in source code form, as it exists at the time of the request, along with the source code and related documentation for any derivative works.\n",
    " \n",
    "Licensee shall reproduce all copyright notices and other proprietary markings or legends contained within or on the Evidation Code on any copies made.\n",
    "\n",
    "Licensee shall not knowingly infringe upon the intellectual property rights of any third party when making Derivative Works to the Evidation Code.\n",
    "\n",
    "Licensee shall not use open source code for development of or in any authorized derivative work of Evidation Code in any manner that would subject the Evidation Code to open source distribution.  To extent there is any open source code in the Evidation Code and there exists a conflict between the this license and any applicable license to open source technology, the provisions of the open source license shall be followed, but only to the minimum extent reasonably necessary to comply with the applicable open source license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; print('Pandas version:', pd.__version__)\n",
    "import numpy as np; print('Numpy version:', np.__version__)\n",
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "import os\n",
    "USE_CORES = os.cpu_count() - 1\n",
    "print('Using cores=', USE_CORES)\n",
    "\n",
    "pd.set_option('max.rows', 100)\n",
    "pd.set_option('max.columns', 300)\n",
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x) #supress scientific notation\n",
    "\n",
    "#pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set DATA and OUTPUT paths here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace argparse args in notebook\n",
    "\n",
    "@dataclass\n",
    "class Args():\n",
    "    hdf_file = '/SET/PATH/HERE/file.hdf' # HDF file with keys `activity` and `survey`\n",
    "    test_csv = None # Can provide `test_participants.csv`\n",
    "    output_dir = '/SET/PATH/HERE/OUTPUT_DIR' # Provide output directory path\n",
    "    use_cores = None # If None, will use N-1 cores \n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancet-RHR method\n",
    "\n",
    "* Using `measurement` & `mask` dataframes and columns:\n",
    "    * `heart_rate__resting_heart_rate` for RHR\n",
    "    * `sleep__asleep__sum` for Sleep\n",
    "    * `active_fitbit__sum` for Wear time\n",
    "* Data density requirements:\n",
    "    * 7-day window for weekly RHR calculation\n",
    "    * Minimum **4** valid RHR values required in window\n",
    "    * Minimum **100** valid-RHR-value days of past data for baseline calculation\n",
    "    * Minimum **1000** minutes of wear-time per valid day\n",
    "* Score & Threshold Rule:\n",
    "    * z-score = (Weekly Avg. RHR/Sleep  - Baseline Avg. RHR/Sleep)/(Baseline Std. Dev. RHR/Sleep) \n",
    "    * **z-RHR > 0.5 AND z-Sleep > -0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists(args.output_dir)):\n",
    "        os.mkdir(args.output_dir)\n",
    "\n",
    "OUTPUT_PATH = os.path.join(args.output_dir, 'lancet_rhr-testset_results.csv')\n",
    "        \n",
    "### Number of cores for multiprocessing\n",
    "USE_CORES = args.use_cores\n",
    "if USE_CORES is None:\n",
    "    USE_CORES = os.cpu_count() - 1\n",
    "\n",
    "### Default keys\n",
    "activity_key = 'activity'\n",
    "labels_key = 'survey'\n",
    "\n",
    "### Define parameters\n",
    "feature_name_rhr='heart_rate__resting_heart_rate'\n",
    "feature_name_sleep='sleep__asleep__sum'\n",
    "feature_name_wear='active_fitbit__sum'\n",
    "measurement_col='measurement'\n",
    "mask_col='mask'\n",
    "window='7d'\n",
    "min_week_valid_days=4\n",
    "min_baseline_valid_days=100\n",
    "min_wear_time_mins=1000\n",
    "rhr_thresh=0.5\n",
    "sleep_thresh=-0.5\n",
    "label_col = 'ili'\n",
    "output_label_col = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lancet_rhr_method(x, feature_name_rhr='heart_rate__resting_heart_rate', feature_name_sleep='sleep__asleep__sum',\n",
    "                      feature_name_wear='active_fitbit__sum', measurement_col='measurement', mask_col='mask',\n",
    "                      window='7d', min_week_valid_days=4, min_baseline_valid_days=100, min_wear_time_mins=1000,\n",
    "                      rhr_thresh=0.5, sleep_thresh=-0.5):\n",
    "    \"\"\" \n",
    "    Input: single-participant time-series data-frame with RHR, Sleep, Wear-time columns\n",
    "    Output: Lancet-RHR decision and scores per date in data-frame\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.sort_index(level=1).droplevel(0) #drop participant_id since rolling/expanding not supported for multi-index\n",
    "    \n",
    "    drop_rhr = ((~x[mask_col, feature_name_rhr]) | (x[measurement_col, feature_name_wear] < min_wear_time_mins)).rename('drop_rhr')\n",
    "    drop_sleep = ((~x[mask_col, feature_name_sleep]) | (x[measurement_col, feature_name_wear] < min_wear_time_mins)).rename('drop_sleep')\n",
    "\n",
    "    valid_rhr = x[measurement_col, feature_name_rhr].mask(drop_rhr).rename('valid_rhr')\n",
    "    valid_sleep = x[measurement_col, feature_name_sleep].mask(drop_sleep).rename('valid_sleep')\n",
    "\n",
    "    baseline_valid_days = (0 + ~drop_rhr).expanding().sum().shift(freq=window).rename('baseline_valid_days')\n",
    "    baseline_rhr_mean = valid_rhr.expanding().mean().shift(freq=window).rename('baseline_rhr_mean') # .mask(baseline_valid_days < min_baseline_valid_days).rename('baseline_rhr_mean') # only those with 100 days\n",
    "    baseline_rhr_stdv = valid_rhr.expanding().std().shift(freq=window).rename('baseline_rhr_stdv') # .mask(baseline_valid_days < min_baseline_valid_days).rename('baseline_rhr_stdv')\n",
    "\n",
    "    baseline_sleep_mean = valid_sleep.expanding().mean().shift(freq=window).rename('baseline_sleep_mean') #.mask(baseline_valid_days < min_baseline_valid_days).rename('baseline_sleep_mean') # only those with 100 days\n",
    "    baseline_sleep_stdv = valid_sleep.expanding().std().shift(freq=window).rename('baseline_sleep_stdv') #.mask(baseline_valid_days < min_baseline_valid_days).rename('baseline_sleep_stdv')\n",
    "\n",
    "\n",
    "    weekly_valid_days = (0 + ~drop_rhr).rolling(window).sum().rename('weekly_valid_days')\n",
    "    weekly_rhr_mean = valid_rhr.rolling(window).mean().rename('weekly_rhr_mean') #.mask(weekly_valid_days < min_week_valid_days).rename('weekly_rhr_mean')\n",
    "    weekly_sleep_mean = valid_sleep.rolling(window).mean().rename('weekly_sleep_mean') #.mask(weekly_valid_days < min_week_valid_days).rename('weekly_sleep_mean')\n",
    "\n",
    "    daily_z_rhr = ((weekly_rhr_mean - baseline_rhr_mean)/baseline_rhr_stdv).rename('daily_z_rhr')\n",
    "    daily_z_sleep = ((weekly_sleep_mean - baseline_sleep_mean)/baseline_sleep_stdv).rename('daily_z_sleep')\n",
    "\n",
    "    lancet_rhr_decision = (0 + ((daily_z_rhr > rhr_thresh) & (daily_z_sleep > sleep_thresh))).rename('lancet_rhr_decision')\n",
    "    lancet_rhr_decision[daily_z_rhr.isna() | daily_z_sleep.isna() | baseline_valid_days < min_baseline_valid_days] = np.nan\n",
    "    \n",
    "    return pd.concat([lancet_rhr_decision, daily_z_rhr, daily_z_sleep, weekly_rhr_mean, weekly_sleep_mean, \n",
    "                      weekly_valid_days, baseline_valid_days, baseline_rhr_mean, baseline_rhr_stdv, \n",
    "                      baseline_sleep_mean, baseline_sleep_stdv, valid_rhr, drop_rhr, valid_sleep, drop_sleep],\n",
    "                      join='outer', axis=1).loc[x.index,:] #return values for dates in original dataframe\n",
    "\n",
    "def lancet_rhr_parallel_apply(x):\n",
    "    y = lancet_rhr_method(x[1])\n",
    "    y.index = pd.MultiIndex.from_product([[x[0]], y.index])\n",
    "    y.index.names = ['participant_id', 'date']\n",
    "    return y\n",
    "\n",
    "def prop_table(x, dropna=True):\n",
    "    \"\"\" Unique values and count/percentage in pandas series\"\"\"\n",
    "    tmp = (x.value_counts(sort=False, dropna=dropna).reset_index()\n",
    "           .merge((100 * x.value_counts(sort=False, normalize=True, dropna=dropna)).round(2).reset_index(), on='index',\n",
    "                  how='inner'))\n",
    "    tmp.columns = [x.name, 'count', 'percent']\n",
    "    tmp = tmp.sort_values('count', ascending=False)\n",
    "    tot = x.notnull().sum() if dropna else len(x)\n",
    "    return tmp.append(pd.DataFrame([['Total', tot, 100]], columns=tmp.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load activity `measurement` and `mask` dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load processed-imputed activity\n",
    "df = pd.read_hdf(args.hdf_file, activity_key)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns.get_level_values(0).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load survey dataframe (for ILI labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load survey\n",
    "mf = pd.read_hdf(args.hdf_file, labels_key)\n",
    "\n",
    "print(mf.shape)\n",
    "mf.columns.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join activity and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.columns = pd.MultiIndex.from_product([['labels'], mf.columns])\n",
    "df = df.join(mf, how='left')\n",
    "print(df.shape)\n",
    "df.columns.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(df.index.get_level_values(1)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with single participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[df.index.get_level_values(0)=='viAz0JRFPhIUyKb1',:].copy()#.droplevel(0)\n",
    "print(x.shape)\n",
    "x.loc[:,idx['measurement', ['heart_rate__resting_heart_rate', 'sleep__asleep__sum', 'active_fitbit__sum']]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.loc[:,idx['measurement', ['heart_rate__resting_heart_rate', 'sleep__asleep__sum', 'active_fitbit__sum']]].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lancet_rhr_method(x)\n",
    "print(y.shape)\n",
    "y[['lancet_rhr_decision', 'daily_z_rhr', 'daily_z_sleep']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[['lancet_rhr_decision', 'daily_z_rhr', 'daily_z_sleep']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with multiple participants and `parallel_apply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.loc[idx[list(df.sample(5).index.get_level_values(0)),:],:]\n",
    "print(tmp.shape)\n",
    "tmp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using cores=', USE_CORES)\n",
    "\n",
    "p = Pool(USE_CORES)\n",
    "stime = time()\n",
    "foo = pd.concat(p.map(lancet_rhr_parallel_apply, tmp.groupby('participant_id')))\n",
    "etime = time()\n",
    "print(f'Time: {etime-stime:.2f}s')\n",
    "print(foo.shape)\n",
    "foo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (MAIN) Run on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = time()\n",
    "out = pd.concat(p.map(lancet_rhr_parallel_apply, df.groupby('participant_id')))\n",
    "etime = time()\n",
    "print(f'Time: {etime-stime:.2f}s')\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NaN/0/1 prediction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_table(out.lancet_rhr_decision, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with day-level ILI labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = mf[[label_col]].rename(columns={label_col: output_label_col})\n",
    "print(tmp.shape)\n",
    "display(tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TANH the z-scores before saving result to deal with infinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tmp.join(out, how='left')\n",
    "out['tanh_daily_z_rhr'] = out.loc[:, 'daily_z_rhr'].apply(np.tanh)\n",
    "out['label'] = out['label'].astype(int)\n",
    "out['score'] = out['lancet_rhr_decision']\n",
    "\n",
    "print(out.shape)\n",
    "display(out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RHR NaN frac={out.daily_z_rhr.isna().sum()/out.shape[0]:.2f}, Sleep NaN frac={out.daily_z_sleep.isna().sum()/out.shape[0]:.2f}')\n",
    "print()\n",
    "pd.concat([out.tanh_daily_z_rhr.describe(), out.daily_z_rhr.describe(), out.daily_z_sleep.describe()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['label', 'score', 'tanh_daily_z_rhr', 'lancet_rhr_decision', 'daily_z_rhr', 'daily_z_sleep',\n",
    "             'weekly_rhr_mean', 'weekly_sleep_mean', 'weekly_valid_days',\n",
    "             'baseline_valid_days', 'baseline_rhr_mean', 'baseline_rhr_stdv',\n",
    "             'baseline_sleep_mean', 'baseline_sleep_stdv', 'valid_rhr', 'drop_rhr', 'valid_sleep', 'drop_sleep']\n",
    "\n",
    "out = out[col_order]\n",
    "print(out.shape)\n",
    "display(out.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to `pickle` and results for test participants to `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_pickle(OUTPUT_PATH.replace('testset_results.csv', 'full_output.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare dataframe for saving results\n",
    "dump = out.reset_index()[['participant_id', 'date', 'label', 'score', 'tanh_daily_z_rhr']]\n",
    "\n",
    "## SAVE ALL RESULT CSV\n",
    "dump.to_csv(OUTPUT_PATH.replace('testset', 'all'), index=None)\n",
    "\n",
    "## Load test participants list & Save result for test set only\n",
    "if args.test_csv is not None:\n",
    "    test_idx = pd.read_csv(args.test_csv)\n",
    "\n",
    "    dump[dump.participant_id.isin(test_idx.iloc[:,0])].to_csv(OUTPUT_PATH, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and performance\n",
    "\n",
    "### Lancet-RHR method makes a prediction 42% of the time with recall of 30% (precision 7%) for ILI days\n",
    "\n",
    "* Does not use imputed values\n",
    "* Min. 100 \"valid\" days for baseline stats (wear-time > 1000 mins and RHR available for day to be \"valid\")\n",
    "* Min. 4 \"valid\" days in a week for weekly stats\n",
    "* Rule: z-RHR > 0.5 SD and z-Sleep > -0.5 SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(out.label, out.score, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(out.label, out.score, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, classification_report, average_precision_score, plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = out.lancet_rhr_decision.notna()\n",
    "y_true = out.loc[keep, 'label']\n",
    "y_pred = out.loc[keep, 'lancet_rhr_decision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rhr_auroc = roc_auc_score(y_true, y_pred)\n",
    "out_rhr_avgprec = average_precision_score(y_true, y_pred)\n",
    "print(f'AUROC = {out_rhr_auroc:.3f}')\n",
    "print(f'Avg. Precision = {out_rhr_avgprec:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
